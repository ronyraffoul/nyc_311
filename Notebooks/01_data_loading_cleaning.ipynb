{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC 311 Service Request Response Time Prediction\n",
    "# Notebook 1: Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import gc  # For garbage collection\n",
    "import pandas as pd  # For compatibility with visualization libs if needed\n",
    "pl.enable_string_cache()\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data path to sys which is a level above the current directory\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "# add the parent directory to sys.path\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datetime import datetime\n",
    "\n",
    "def load_nyc_311_data(file_path):\n",
    "    print(f\"Loading data from {file_path}...\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    schema_overrides = {\n",
    "        \"unique_key\": pl.Utf8,\n",
    "        \"created_date\": pl.Datetime,\n",
    "        \"closed_date\": pl.Datetime,\n",
    "        \"agency\": pl.Categorical,\n",
    "        \"agency_name\": pl.Categorical,\n",
    "        \"complaint_type\": pl.Categorical,\n",
    "        \"descriptor\": pl.Categorical,\n",
    "        \"status\": pl.Categorical,\n",
    "        \"due_date\": pl.Datetime,\n",
    "        \"resolution_action_updated_date\": pl.Datetime,\n",
    "        \"location_type\": pl.Categorical,\n",
    "        \"incident_zip\": pl.Utf8,\n",
    "        \"incident_address\": pl.Utf8,\n",
    "        \"street_name\": pl.Utf8,\n",
    "        \"cross_street_1\": pl.Utf8,\n",
    "        \"cross_street_2\": pl.Utf8,\n",
    "        \"intersection_street_1\": pl.Utf8,\n",
    "        \"intersection_street_2\": pl.Utf8,\n",
    "        \"address_type\": pl.Categorical,\n",
    "        \"city\": pl.Utf8,\n",
    "        \"landmark\": pl.Utf8,\n",
    "        \"facility_type\": pl.Utf8,\n",
    "        \"community_board\": pl.Categorical,\n",
    "        \"bbl\": pl.Utf8,\n",
    "        \"borough\": pl.Categorical,\n",
    "        \"x_coordinate_state_plane\": pl.Float64,\n",
    "        \"y_coordinate_state_plane\": pl.Float64,\n",
    "        \"open_data_channel_type\": pl.Categorical,\n",
    "        \"latitude\": pl.Float64,\n",
    "        \"longitude\": pl.Float64,\n",
    "        \"location\": pl.Utf8,\n",
    "        \"park_facility_name\": pl.Utf8,\n",
    "        \"park_borough\": pl.Utf8,\n",
    "        \"vehicle_type\": pl.Utf8,\n",
    "        \"taxi_company_borough\": pl.Utf8,\n",
    "        \"taxi_pick_up_location\": pl.Utf8,\n",
    "        \"bridge_highway_name\": pl.Utf8,\n",
    "        \"bridge_highway_direction\": pl.Utf8,\n",
    "        \"road_ramp\": pl.Utf8,\n",
    "        \"bridge_highway_segment\": pl.Utf8\n",
    "    }\n",
    "    \n",
    "    df = pl.scan_csv(\n",
    "        file_path,\n",
    "        schema_overrides=schema_overrides,\n",
    "        null_values=[\"N/A\", \"Unknown\", \"Unkno\", \"\", \"null\"],\n",
    "        infer_schema_length=1000000,\n",
    "        ignore_errors=True\n",
    "    )\n",
    "    \n",
    "    print(\"Data schema:\")\n",
    "    schema = df.collect_schema()\n",
    "    for name, dtype in schema.items():\n",
    "        print(f\"{name}: {dtype}\")\n",
    "    \n",
    "    row_count = df.select(pl.len()).collect()[0, 0]\n",
    "    print(f\"Total rows: {row_count:,}\")\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print(f\"Data loaded in {(end_time - start_time).total_seconds():.2f} seconds\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../NYC_311_Data/NYC_311_complete.csv...\n",
      "Data schema:\n",
      ":@computed_region_7mpf_4k6g: Int64\n",
      ":@computed_region_92fq_4b7q: Int64\n",
      ":@computed_region_efsh_h5xi: Int64\n",
      ":@computed_region_f5dn_yrer: Int64\n",
      ":@computed_region_sbqj_enih: Int64\n",
      ":@computed_region_yeji_bk3q: Int64\n",
      "address_type: Categorical(ordering='physical')\n",
      "agency: Categorical(ordering='physical')\n",
      "agency_name: Categorical(ordering='physical')\n",
      "bbl: String\n",
      "borough: Categorical(ordering='physical')\n",
      "bridge_highway_direction: String\n",
      "bridge_highway_name: String\n",
      "bridge_highway_segment: String\n",
      "city: String\n",
      "closed_date: Datetime(time_unit='us', time_zone=None)\n",
      "community_board: Categorical(ordering='physical')\n",
      "complaint_type: Categorical(ordering='physical')\n",
      "created_date: Datetime(time_unit='us', time_zone=None)\n",
      "cross_street_1: String\n",
      "cross_street_2: String\n",
      "descriptor: Categorical(ordering='physical')\n",
      "due_date: Datetime(time_unit='us', time_zone=None)\n",
      "facility_type: String\n",
      "incident_address: String\n",
      "incident_zip: String\n",
      "intersection_street_1: String\n",
      "intersection_street_2: String\n",
      "landmark: String\n",
      "latitude: Float64\n",
      "location: String\n",
      "location_type: Categorical(ordering='physical')\n",
      "longitude: Float64\n",
      "open_data_channel_type: Categorical(ordering='physical')\n",
      "park_borough: String\n",
      "park_facility_name: String\n",
      "resolution_action_updated_date: Datetime(time_unit='us', time_zone=None)\n",
      "resolution_description: String\n",
      "road_ramp: String\n",
      "status: Categorical(ordering='physical')\n",
      "street_name: String\n",
      "taxi_company_borough: String\n",
      "taxi_pick_up_location: String\n",
      "unique_key: String\n",
      "vehicle_type: String\n",
      "x_coordinate_state_plane: Float64\n",
      "y_coordinate_state_plane: Float64\n",
      "Total rows: 37,220,000\n",
      "Data loaded in 16.36 seconds\n"
     ]
    }
   ],
   "source": [
    "# Path to the data file - adjust as needed\n",
    "data_file = \"../NYC_311_Data/NYC_311_complete.csv\"\n",
    "\n",
    "# Load data\n",
    "df_lazy = load_nyc_311_data(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 47)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>:@computed_region_7mpf_4k6g</th><th>:@computed_region_92fq_4b7q</th><th>:@computed_region_efsh_h5xi</th><th>:@computed_region_f5dn_yrer</th><th>:@computed_region_sbqj_enih</th><th>:@computed_region_yeji_bk3q</th><th>address_type</th><th>agency</th><th>agency_name</th><th>bbl</th><th>borough</th><th>bridge_highway_direction</th><th>bridge_highway_name</th><th>bridge_highway_segment</th><th>city</th><th>closed_date</th><th>community_board</th><th>complaint_type</th><th>created_date</th><th>cross_street_1</th><th>cross_street_2</th><th>descriptor</th><th>due_date</th><th>facility_type</th><th>incident_address</th><th>incident_zip</th><th>intersection_street_1</th><th>intersection_street_2</th><th>landmark</th><th>latitude</th><th>location</th><th>location_type</th><th>longitude</th><th>open_data_channel_type</th><th>park_borough</th><th>park_facility_name</th><th>resolution_action_updated_date</th><th>resolution_description</th><th>road_ramp</th><th>status</th><th>street_name</th><th>taxi_company_borough</th><th>taxi_pick_up_location</th><th>unique_key</th><th>vehicle_type</th><th>x_coordinate_state_plane</th><th>y_coordinate_state_plane</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>cat</td><td>cat</td><td>cat</td><td>str</td><td>cat</td><td>str</td><td>str</td><td>str</td><td>str</td><td>datetime[μs]</td><td>cat</td><td>cat</td><td>datetime[μs]</td><td>str</td><td>str</td><td>cat</td><td>datetime[μs]</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>cat</td><td>f64</td><td>cat</td><td>str</td><td>str</td><td>datetime[μs]</td><td>str</td><td>str</td><td>cat</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>57</td><td>38</td><td>18182</td><td>36</td><td>57</td><td>2</td><td>&quot;ADDRESS&quot;</td><td>&quot;NYPD&quot;</td><td>&quot;New York City Police Departmen…</td><td>&quot;3026997501&quot;</td><td>&quot;BROOKLYN&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;BROOKLYN&quot;</td><td>2025-02-20 09:46:41</td><td>&quot;01 BROOKLYN&quot;</td><td>&quot;Illegal Parking&quot;</td><td>2025-02-20 09:18:31</td><td>&quot;GRAHAM AVENUE&quot;</td><td>&quot;ECKFORD STREET&quot;</td><td>&quot;Blocked Crosswalk&quot;</td><td>null</td><td>null</td><td>&quot;247 DRIGGS AVENUE&quot;</td><td>&quot;11222&quot;</td><td>&quot;GRAHAM AVENUE&quot;</td><td>&quot;ECKFORD STREET&quot;</td><td>&quot;DRIGGS AVENUE&quot;</td><td>40.722686</td><td>&quot;{&#x27;latitude&#x27;: &#x27;40.7226864471804…</td><td>&quot;Street/Sidewalk&quot;</td><td>-73.947772</td><td>&quot;MOBILE&quot;</td><td>&quot;BROOKLYN&quot;</td><td>&quot;Unspecified&quot;</td><td>2025-02-20 09:46:44</td><td>&quot;The Police Department responde…</td><td>null</td><td>&quot;Closed&quot;</td><td>&quot;DRIGGS AVENUE&quot;</td><td>null</td><td>null</td><td>&quot;64141859&quot;</td><td>null</td><td>998727.0</td><td>202575.0</td></tr><tr><td>44</td><td>11</td><td>13509</td><td>17</td><td>44</td><td>2</td><td>&quot;ADDRESS&quot;</td><td>&quot;HPD&quot;</td><td>&quot;Department of Housing Preserva…</td><td>&quot;3050260070&quot;</td><td>&quot;BROOKLYN&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;BROOKLYN&quot;</td><td>2025-02-20 19:36:41</td><td>&quot;09 BROOKLYN&quot;</td><td>&quot;HEAT/HOT WATER&quot;</td><td>2025-02-20 09:18:30</td><td>null</td><td>null</td><td>&quot;ENTIRE BUILDING&quot;</td><td>null</td><td>null</td><td>&quot;552 FLATBUSH AVENUE&quot;</td><td>&quot;11225&quot;</td><td>null</td><td>null</td><td>null</td><td>40.660528</td><td>&quot;{&#x27;latitude&#x27;: &#x27;40.6605280296451…</td><td>&quot;RESIDENTIAL BUILDING&quot;</td><td>-73.960644</td><td>&quot;ONLINE&quot;</td><td>&quot;BROOKLYN&quot;</td><td>&quot;Unspecified&quot;</td><td>2025-02-20 00:00:00</td><td>&quot;The Department of Housing Pres…</td><td>null</td><td>&quot;Closed&quot;</td><td>&quot;FLATBUSH AVENUE&quot;</td><td>null</td><td>null</td><td>&quot;64140044&quot;</td><td>null</td><td>995169.0</td><td>179927.0</td></tr><tr><td>28</td><td>12</td><td>11270</td><td>43</td><td>28</td><td>5</td><td>&quot;ADDRESS&quot;</td><td>&quot;HPD&quot;</td><td>&quot;Department of Housing Preserva…</td><td>&quot;2041637501&quot;</td><td>&quot;BRONX&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;BRONX&quot;</td><td>2025-02-20 17:56:49</td><td>&quot;10 BRONX&quot;</td><td>&quot;HEAT/HOT WATER&quot;</td><td>2025-02-20 09:18:27</td><td>null</td><td>null</td><td>&quot;ENTIRE BUILDING&quot;</td><td>null</td><td>null</td><td>&quot;1725 EDISON AVENUE&quot;</td><td>&quot;10461&quot;</td><td>null</td><td>null</td><td>null</td><td>40.845857</td><td>&quot;{&#x27;latitude&#x27;: &#x27;40.8458565695313…</td><td>&quot;RESIDENTIAL BUILDING&quot;</td><td>-73.832637</td><td>&quot;ONLINE&quot;</td><td>&quot;BRONX&quot;</td><td>&quot;Unspecified&quot;</td><td>2025-02-20 00:00:00</td><td>&quot;The Department of Housing Pres…</td><td>null</td><td>&quot;Closed&quot;</td><td>&quot;EDISON AVENUE&quot;</td><td>null</td><td>null</td><td>&quot;64139849&quot;</td><td>null</td><td>1.030555e6</td><td>247490.0</td></tr><tr><td>22</td><td>39</td><td>13098</td><td>47</td><td>22</td><td>4</td><td>&quot;ADDRESS&quot;</td><td>&quot;NYPD&quot;</td><td>&quot;New York City Police Departmen…</td><td>&quot;1021790511&quot;</td><td>&quot;MANHATTAN&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;NEW YORK&quot;</td><td>2025-02-21 06:21:25</td><td>&quot;12 MANHATTAN&quot;</td><td>&quot;Blocked Driveway&quot;</td><td>2025-02-20 09:18:09</td><td>&quot;WEST&nbsp;&nbsp;190 STREET&quot;</td><td>&quot;CABRINI BOULEVARD&quot;</td><td>&quot;Partial Access&quot;</td><td>null</td><td>null</td><td>&quot;701 FORT WASHINGTON AVENUE&quot;</td><td>&quot;10040&quot;</td><td>&quot;WEST&nbsp;&nbsp;190 STREET&quot;</td><td>&quot;CABRINI BOULEVARD&quot;</td><td>&quot;FORT WASHINGTON AVENUE&quot;</td><td>40.8578</td><td>&quot;{&#x27;latitude&#x27;: &#x27;40.8578003775818…</td><td>&quot;Street/Sidewalk&quot;</td><td>-73.9351</td><td>&quot;PHONE&quot;</td><td>&quot;MANHATTAN&quot;</td><td>&quot;Unspecified&quot;</td><td>2025-02-21 06:21:29</td><td>&quot;The Police Department responde…</td><td>null</td><td>&quot;Closed&quot;</td><td>&quot;FORT WASHINGTON AVENUE&quot;</td><td>null</td><td>null</td><td>&quot;64141525&quot;</td><td>null</td><td>1.002203e6</td><td>251804.0</td></tr><tr><td>61</td><td>6</td><td>24332</td><td>41</td><td>61</td><td>3</td><td>&quot;ADDRESS&quot;</td><td>&quot;DOT&quot;</td><td>&quot;Department of Transportation&quot;</td><td>&quot;4108670050&quot;</td><td>&quot;QUEENS&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;HOLLIS&quot;</td><td>2025-02-20 16:32:04</td><td>&quot;12 QUEENS&quot;</td><td>&quot;Street Condition&quot;</td><td>2025-02-20 09:18:08</td><td>&quot;100 AVENUE&quot;</td><td>&quot;104 AVENUE&quot;</td><td>&quot;Blocked - Construction&quot;</td><td>null</td><td>null</td><td>&quot;100-35 200 STREET&quot;</td><td>&quot;11423&quot;</td><td>&quot;100 AVENUE&quot;</td><td>&quot;104 AVENUE&quot;</td><td>&quot;200 STREET&quot;</td><td>40.710279</td><td>&quot;{&#x27;latitude&#x27;: &#x27;40.7102791635360…</td><td>&quot;Street&quot;</td><td>-73.759318</td><td>&quot;ONLINE&quot;</td><td>&quot;QUEENS&quot;</td><td>&quot;Unspecified&quot;</td><td>2025-02-20 16:32:08</td><td>&quot;The Department of Transportati…</td><td>null</td><td>&quot;Closed&quot;</td><td>&quot;200 STREET&quot;</td><td>null</td><td>null</td><td>&quot;64144217&quot;</td><td>null</td><td>1.050976e6</td><td>198142.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 47)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ :@compute ┆ :@compute ┆ :@compute ┆ :@compute ┆ … ┆ unique_ke ┆ vehicle_t ┆ x_coordin ┆ y_coordi │\n",
       "│ d_region_ ┆ d_region_ ┆ d_region_ ┆ d_region_ ┆   ┆ y         ┆ ype       ┆ ate_state ┆ nate_sta │\n",
       "│ 7mpf_4k6g ┆ 92fq_4b7q ┆ efsh_h5xi ┆ f5dn_yrer ┆   ┆ ---       ┆ ---       ┆ _plane    ┆ te_plane │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ str       ┆ str       ┆ ---       ┆ ---      │\n",
       "│ i64       ┆ i64       ┆ i64       ┆ i64       ┆   ┆           ┆           ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 57        ┆ 38        ┆ 18182     ┆ 36        ┆ … ┆ 64141859  ┆ null      ┆ 998727.0  ┆ 202575.0 │\n",
       "│ 44        ┆ 11        ┆ 13509     ┆ 17        ┆ … ┆ 64140044  ┆ null      ┆ 995169.0  ┆ 179927.0 │\n",
       "│ 28        ┆ 12        ┆ 11270     ┆ 43        ┆ … ┆ 64139849  ┆ null      ┆ 1.030555e ┆ 247490.0 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 6         ┆          │\n",
       "│ 22        ┆ 39        ┆ 13098     ┆ 47        ┆ … ┆ 64141525  ┆ null      ┆ 1.002203e ┆ 251804.0 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 6         ┆          │\n",
       "│ 61        ┆ 6         ┆ 24332     ┆ 41        ┆ … ┆ 64144217  ┆ null      ┆ 1.050976e ┆ 198142.0 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 6         ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display first few rows to verify data loading\n",
    "print(\"Preview of data:\")\n",
    "df_sample = df_lazy.limit(5).collect()\n",
    "display(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Keeping only relevant columns, dropping rows with null closed dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "def clean_nyc_311_data(df_lazy):\n",
    "    \"\"\"\n",
    "    Clean NYC 311 data by calculating response time, filtering invalid rows,\n",
    "    and selecting relevant columns for prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_lazy : pl.LazyFrame\n",
    "        Loaded NYC 311 data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pl.LazyFrame\n",
    "        Cleaned data ready for response time prediction\n",
    "    \"\"\"\n",
    "\n",
    "    # First, filter out rows with null 'closed_date'\n",
    "    df_cleaned = df_lazy.filter(\n",
    "        pl.col('closed_date').is_not_null()\n",
    "    )\n",
    "    \n",
    "    # Calculate response time in multiple units\n",
    "    df_cleaned = df_cleaned.with_columns([\n",
    "        (pl.col('closed_date') - pl.col('created_date')).dt.total_seconds().alias('response_time_seconds'),\n",
    "        ((pl.col('closed_date') - pl.col('created_date')).dt.total_seconds() / 60).alias('response_time_minutes'),\n",
    "        ((pl.col('closed_date') - pl.col('created_date')).dt.total_seconds() / 3600).alias('response_time_hours')\n",
    "    ])\n",
    "    \n",
    "    # Filter rows to keep only valid data\n",
    "    df_cleaned = df_cleaned.filter(\n",
    "        pl.col('response_time_hours').is_not_null() &  # Ensures closed_date and created_date are valid\n",
    "        (pl.col('response_time_hours') >= 0) &         # No negative response times\n",
    "        (pl.col('response_time_hours') <= 8760) &      # Max 365 days (365 * 24 hours)\n",
    "        pl.col('agency').is_not_null() &               # Key feature\n",
    "        pl.col('complaint_type').is_not_null() &       # Key feature\n",
    "        pl.col('borough').is_not_null()                # Key feature\n",
    "    )\n",
    "    \n",
    "    # Select only the relevant columns for prediction\n",
    "    columns_to_keep = [\n",
    "        'created_date',           # For temporal features\n",
    "        'closed_date',            # For temporal features\n",
    "        'agency',                 # Responding agency\n",
    "        'complaint_type',         # Type of complaint\n",
    "        'descriptor',             # Additional detail\n",
    "        'location_type',          # Type of location\n",
    "        'incident_zip',           # Zip code\n",
    "        'borough',                # Borough\n",
    "        'open_data_channel_type', # Submission channel\n",
    "        'latitude',               # Geographic coordinate\n",
    "        'longitude',              # Geographic coordinate\n",
    "        'community_board',        # Local governance area\n",
    "        'response_time_seconds',  # Response in seconds\n",
    "        'response_time_minutes',  # Response in minutes\n",
    "        'response_time_hours'     # Target variable\n",
    "    ]\n",
    "    \n",
    "    df_cleaned = df_cleaned.select(columns_to_keep)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Clean data\n",
    "df_cleaned_lazy = clean_nyc_311_data(df_lazy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_lazy = df_cleaned_lazy.drop_nulls(subset=['response_time_hours', 'created_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['agency', 'complaint_type', 'descriptor', 'location_type', \n",
    "                    'incident_zip', 'borough', 'open_data_channel_type', 'community_board']\n",
    "\n",
    "\n",
    "df_cleaned_lazy = df_cleaned_lazy.with_columns([pl.col(col).fill_null('Unknown') for col in categorical_cols])\n",
    "\n",
    "# Drop rows with missing coordinates\n",
    "df_cleaned_lazy = df_cleaned_lazy.drop_nulls(subset=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates using polars\n",
    "df_cleaned_lazy = df_cleaned_lazy.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower_bound is -209.3451388888889 and upper_bound is 353.79375000000005\n"
     ]
    }
   ],
   "source": [
    "Q1 = df_cleaned_lazy.select(pl.col(\"response_time_hours\").quantile(0.25)).collect()[0, 0]\n",
    "Q3 = df_cleaned_lazy.select(pl.col(\"response_time_hours\").quantile(0.75)).collect()[0, 0]\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"lower_bound is {lower_bound} and upper_bound is {upper_bound}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_lazy = df_cleaned_lazy.filter(\n",
    "    pl.col(\"response_time_hours\").is_between(lower_bound, upper_bound)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where response_time_minutes is 0\n",
    "df_cleaned_lazy = df_cleaned_lazy.filter(pl.col(\"response_time_minutes\") > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical columns\n",
    "categorical_cols = [\n",
    "    'agency',\n",
    "    'complaint_type',\n",
    "    'descriptor',\n",
    "    'location_type',\n",
    "    'incident_zip',\n",
    "    'borough',\n",
    "    'open_data_channel_type',\n",
    "    'community_board'\n",
    "]\n",
    "\n",
    "# return unique values for each categorical column as key value pairs\n",
    "unique_values = {col: df_cleaned_lazy.select(pl.col(col).unique()).collect() for col in categorical_cols}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the Polars DataFrames to a dictionary with lists of unique values\n",
    "unique_values_dict = {}\n",
    "for col, pl_df in unique_values.items():\n",
    "    unique_values_dict[col] = pl_df.to_series(0).to_list()\n",
    "\n",
    "# Determine the maximum list length for alignment\n",
    "max_len = max(len(vals) for vals in unique_values_dict.values())\n",
    "\n",
    "# Create a dictionary with padded values\n",
    "data_for_csv = {\n",
    "    col: vals + [None] * (max_len - len(vals))\n",
    "    for col, vals in unique_values_dict.items()\n",
    "}\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "csv_df = pd.DataFrame(data_for_csv)\n",
    "\n",
    "# Save as CSV\n",
    "csv_df.to_csv(\"unique_values.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all categorical columns are cast to Utf8 before string operations\n",
    "df_cleaned_lazy = df_cleaned_lazy.with_columns(\n",
    "    pl.col(\"agency\").cast(pl.Utf8),\n",
    "    pl.col(\"complaint_type\").cast(pl.Utf8),\n",
    "    pl.col(\"descriptor\").cast(pl.Utf8),\n",
    "    pl.col(\"location_type\").cast(pl.Utf8),\n",
    "    pl.col(\"incident_zip\").cast(pl.Utf8),  # Even though it's zip codes, treat as string for consistency\n",
    "    pl.col(\"borough\").cast(pl.Utf8),\n",
    "    pl.col(\"open_data_channel_type\").cast(pl.Utf8),\n",
    "    pl.col(\"community_board\").cast(pl.Utf8)\n",
    ").with_columns(\n",
    "    # Agency: Handle missing values and clean\n",
    "    pl.col(\"agency\")\n",
    "    .fill_null(\"Unknown\")\n",
    "    .str.strip_chars()\n",
    "    .replace(\"\", \"Unknown\"),\n",
    "    # Complaint_type: Standardize to title case\n",
    "    pl.col(\"complaint_type\")\n",
    "    .str.to_titlecase(),\n",
    "    # Descriptor: Standardize to title case\n",
    "    pl.col(\"descriptor\")\n",
    "    .str.to_titlecase(),\n",
    "    # Location_type: Standardize and fix typo\n",
    "    pl.col(\"location_type\")\n",
    "    .str.to_titlecase()\n",
    "    .str.replace(\"Comercial\", \"Commercial\"),\n",
    "    # Incident_zip: Validate NYC zip codes\n",
    "    pl.col(\"incident_zip\")\n",
    "    .fill_null(\"Unknown\"),\n",
    "    # Borough: Handle missing values\n",
    "    pl.col(\"borough\")\n",
    "    .fill_null(\"Unknown\")\n",
    "    .str.strip_chars()\n",
    "    .replace(\"\", \"Unknown\"),\n",
    "    # Open_data_channel_type: Standardize to title case\n",
    "    pl.col(\"open_data_channel_type\")\n",
    "    .fill_null(\"Unknown\")\n",
    "    .str.strip_chars()\n",
    "    .str.to_uppercase()\n",
    "    .replace(\"\", \"Unknown\"),\n",
    "    # Community_board: Standardize to title case    \n",
    "    pl.col(\"community_board\")\n",
    "    .str.to_titlecase()\n",
    "    .fill_null(\"Unknown\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_cleaned_lazy.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.write_csv(\"../NYC_311_Data/outputs/nyc_311_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
